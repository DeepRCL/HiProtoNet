################### Experiment information ######################
description: ProtoASNet model based on Xprotonet for video data, but has abstain logits
run_name: "ProtoASNet_Video"
agent: "Video_XProtoNet_e2e"
wandb_mode: 'online'  # one of "online", "offline" or "disabled". disabled turns wandb logging off! good for testing
abstain_class: True

################## Model information ##########################
model: &model
  checkpoint_path: ''
  name: "Video_XProtoNet"
  base_architecture: 'resnet2p1d_18'  # backbone
  backbone_last_layer_num: -3
  pretrained: True
  prototype_shape: (40, 256, 1, 1, 1)  # Modify first element to select total # of prototypes (dividable by num_classes)
  num_classes: 4
  feat_range_type: "Sigmoid"   # can be "Tanh" or "Sigmoid" or "CLIP-style"
  push_at_end: False
################## Training information ##########################
train: &train
  seed: 200
  num_train_epochs: 50
  save: True
  save_step: null
  num_warm_epochs: 5
  batch_size: 5   # TODO Check
  accumulation_steps: 20  # TODO Check
  push_start: 10
  push_rate: 5 # epochs
  num_workers: 8

  criterion:
#    FocalLoss:  # TODO Modify to multi-class
#      loss_weight: 1
#      gamma: 2
#      reduction: 'mean'
    CeLoss:  # will be used if (abstain_class == False)
      loss_weight: 1
      reduction: 'mean'
    CeLossAbstain:  # will be used if (abstain_class == True)
        loss_weight: 1
        ab_weight: 0.1
        ab_logitpath: 'joined'
        reduction: 'mean'
    ClusterRoiFeat:
      loss_weight: 0.04
      reduction: 'mean'
    SeparationRoiFeat:
      loss_weight: 0.01
      reduction: 'mean'
    OrthogonalityLoss:
      loss_weight: 0.0
      mode: 'per_class'  # to encourage diversity in each class ('per_class'), or overal ('all')
    Lnorm_occurrence:
      p: 2
      loss_weight: 0.0 # 1e-4
      reduction: 'mean'
    trans_occurrence:
      loss_weight: 0.0001 # 1e-4
      reduction: 'mean'
    Lnorm_FC:
      p: 1
      loss_weight: 0.0001 # 1e-4

  optimizer: &optimizer
    name: 'Adam'
    mode: 'lr_disjoint'  # can be lr_same/lr_disjoint
    lr_same: 0.0001  # 1e-4
    lr_disjoint:
      cnn_backbone: 0.0001
      add_on_layers: 0.0001
      occurrence_module: 0.0001
      prototype_vectors: 0.003
      last_layer: 0.0001
    lr_last_layer_only: 0.000001 # 1e-6

  lr_schedule: &lr_schedule   # for joint_optimizer and last_layer_optimizer only
    # TODO names
    name: 'CosineAnnealingLR' # one of ReduceLROnPlateau, StepLR, CosineAnnealingLR
    StepLR:
      step_size: 5
      gamma: 0.8   # ProtoPNet used 0.1
    ReduceLROnPlateau:
      mode: 'max'  # used for F1 score
      factor: 0.5  # Factor by which the learning rate will be reduced
      patience: 5 # Number of epochs with no improvement after which learning rate will be reduced
      threshold: 0.0001  # Threshold for measuring the new optimum, to only focus on significant changes
      cooldown: 2
      min_lr: 0.000001  # 1e-6
      verbose: True
    CosineAnnealingLR:
      eta_min: 0.000001  # 1e-6

#################### Data information #######################
data: &data   #TODO modify this according to your dataset class and dataloder needs
  name: "<dataset name>"
  data_info_file: 'data/<dataset name>/<dataset-csv-info>.csv'
  sample_size: null
  sampler: 'AS'  # one of 'AS', 'random', 'bicuspid', 'AVA'
  view: 'all'   # one of  psax, plax, all

  augmentation: True
  transform_rotate_degrees: 15
  transform_min_crop_ratio: 0.7
  transform_time_dilation: 0.2
  normalize: True
  img_size: 112
  frames: 32  # 1 for image-based, 2 or more for video-based
  iterate_intervals: True # true if we get multiple images/videos in sequence during inference
  interval_unit: 'cycle' # image/second/cycle
  interval_quant: 1.0