################### Experiment information ######################
description: end-to-end version of the ProtoPNet model
run_name: "ProtoPNet"
agent: "ProtoPNet_Base"
wandb_mode: 'online'  # one of "online", "offline" or "disabled". disabled turns wandb logging off! good for testing
abstain_class: False

################## Model information ##########################
model: &model
  checkpoint_path: ''
  name: "ProtoPNet"
  base_architecture: 'resnet18'  # backbone
  pretrained: True
  prototype_shape: (30, 256, 1, 1)  # Modify first element to select total # of prototypes (dividable by num_classes)
  num_classes: 3
  prototype_activation_function: 'linear'
  add_on_layers_type: 'regular'
  feat_range_type: "Sigmoid"   # can be "Tanh" or "Sigmoid" or "CLIP-style"

################## Training information ##########################
train: &train
  seed: 200
  num_train_epochs: 50
  save: True
  save_step: null
  num_warm_epochs: 5
  batch_size: 20
  accumulation_steps: 5
  push_start: 10
  push_rate: 5 # epochs
  last_layer_finetuning_steps: 5   # they had 20!
  num_workers: 8

  criterion:
    CeLoss:
      loss_weight: 1
      reduction: 'mean'
    ClusterPatch:
      loss_weight: 0.8
      reduction: 'mean'
    SeparationPatch:
      loss_weight: 0.08
      strategy: "all"  # can be "all" (for all other classes) or "closest" (for only the closest class)
      normalize: True  # only works when strategy is "all"
      reduction: 'mean'
    Lnorm_FC:
      p: 1
      loss_weight: 0.0001 # 1e-4

  optimizer: &optimizer
    name: 'Adam'
    joint_lrs:
      cnn_backbone: 0.0001 # 1e-4,
      add_on_layers: 0.003 # 3e-3
      prototype_vectors: 0.003 # 3e-3
    warm_lrs:
      add_on_layers: 0.003 # 3e-3,
      prototype_vectors: 0.003 # 3e-3
    last_layer_lr: 0.0001 # 1e-4

  lr_schedule: &lr_schedule   # for joint_optimizer only  TODO try for last_layer_optimizer too
    name: 'StepLR' # one of ReduceLROnPlateau, StepLR, CosineAnnealingLR
    StepLR:
      step_size: 5
      gamma: 0.9   # ProtoPNet used 0.1
    ReduceLROnPlateau:
      mode: 'max'  # used for F1 score
      factor: 0.5  # Factor by which the learning rate will be reduced
      patience: 5 # Number of epochs with no improvement after which learning rate will be reduced
      threshold: 0.0001  # Threshold for measuring the new optimum, to only focus on significant changes
      cooldown: 2
      min_lr: 0.000001  # 1e-6
      verbose: True
    CosineAnnealingLR:
      eta_min: 0.000001  # 1e-6
#################### Data information #######################
data: &data   #TODO modify this according to your dataset class and dataloder needs
  name: "<dataset name>"
  data_info_file: 'data/<dataset name>/<dataset-csv-info>.csv'
  sample_size: null
  sampler: 'AS'  # one of 'AS', 'random', 'bicuspid', 'AVA'
  view: 'all'   # one of  psax, plax, all

  augmentation: True
  transform_rotate_degrees: 15
  transform_min_crop_ratio: 0.7
  transform_time_dilation: 0.2
  normalize: True
  img_size: 224
  frames: 1  # 1 for image-based, 2 or more for video-based
  iterate_intervals: True # true if we get multiple images/videos in sequence during inference
  interval_unit: 'image' # image/second/cycle
  interval_quant: 1.0